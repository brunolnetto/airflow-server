services:
  postgres:
    image: postgres:{{ postgres_version }}
    environment:
      POSTGRES_USER: {{ postgres_user }}
      POSTGRES_PASSWORD: {{ postgres_password }}
      POSTGRES_DB: {{ postgres_db }}
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:{{ redis_version }}

  airflow-webserver:
    image: apache/airflow:{{ airflow_version }}
    entrypoint: ["/entrypoint.sh"]
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://{{ postgres_user }}:{{ postgres_password }}@postgres/{{ postgres_db }}
      AIRFLOW__CORE__LOAD_EXAMPLES: '{{ load_examples }}'
      AIRFLOW__CORE__FERNET_KEY: '{{ fernet_key }}'
      AIRFLOW__CORE__EXECUTOR: {{ executor }}
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: '{{ dags_are_paused }}'
    depends_on:
      - postgres
      - redis
    ports:
      - "8080:8080"
    command: webserver

  airflow-scheduler:
    image: apache/airflow:{{ airflow_version }}
    entrypoint: ["/entrypoint.sh"]
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://{{ postgres_user }}:{{ postgres_password }}@postgres/{{ postgres_db }}
      AIRFLOW__CORE__LOAD_EXAMPLES: '{{ load_examples }}'
      AIRFLOW__CORE__FERNET_KEY: '{{ fernet_key }}'
      AIRFLOW__CORE__EXECUTOR: {{ executor }}
    depends_on:
      - postgres
      - redis
    command: scheduler

  {% for i in range(num_workers) %}
  airflow-worker-{{ i }}:
    image: apache/airflow:{{ airflow_version }}
    entrypoint: ["/entrypoint.sh"]
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://{{ postgres_user }}:{{ postgres_password }}@postgres/{{ postgres_db }}
      AIRFLOW__CORE__LOAD_EXAMPLES: '{{ load_examples }}'
      AIRFLOW__CORE__FERNET_KEY: '{{ fernet_key }}'
      AIRFLOW__CORE__EXECUTOR: {{ executor }}
    depends_on:
      - postgres
      - redis
    command: airflow celery worker
  {% endfor %}

volumes:
  postgres_data:
